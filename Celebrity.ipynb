{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\n\n# set the random seed for reproduction \nSEED=190\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\n# checking if GPU is available or not\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-18T08:30:29.053564Z","iopub.execute_input":"2023-02-18T08:30:29.054061Z","iopub.status.idle":"2023-02-18T08:30:31.629582Z","shell.execute_reply.started":"2023-02-18T08:30:29.05395Z","shell.execute_reply":"2023-02-18T08:30:31.628638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set directory \nmain_folder = '../input/celeba-dataset/'\nimages_folder = main_folder + 'img_align_celeba/img_align_celeba/'\n\nIMG_WIDTH = 178\nIMG_HEIGHT = 218","metadata":{"execution":{"iopub.status.busy":"2023-02-18T08:30:31.63167Z","iopub.execute_input":"2023-02-18T08:30:31.632705Z","iopub.status.idle":"2023-02-18T08:30:31.641589Z","shell.execute_reply.started":"2023-02-18T08:30:31.632667Z","shell.execute_reply":"2023-02-18T08:30:31.640462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comp_path = '/kaggle/input/cs190-winter23-deep-learning-mp1'\ntrain_df = pd.read_csv(os.path.join(comp_path, 'celeba_train.csv'))\nvalid_df = pd.read_csv(os.path.join(comp_path, 'celeba_valid.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-02-18T08:30:31.643797Z","iopub.execute_input":"2023-02-18T08:30:31.644233Z","iopub.status.idle":"2023-02-18T08:30:31.695479Z","shell.execute_reply.started":"2023-02-18T08:30:31.644199Z","shell.execute_reply":"2023-02-18T08:30:31.694398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2023-02-18T08:30:31.698158Z","iopub.execute_input":"2023-02-18T08:30:31.698544Z","iopub.status.idle":"2023-02-18T08:30:31.719633Z","shell.execute_reply.started":"2023-02-18T08:30:31.69851Z","shell.execute_reply":"2023-02-18T08:30:31.718764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data.dataset import Dataset\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\nclass CelebADataset(Dataset):\n    \"\"\"\n        A customized dataset to load the CelebA image dataset.\n    \"\"\"\n    def __init__(self, img_path, imgs, labels, resize=None, inference=False):\n        \"\"\"\n            img_path: str, the directory of celeba dataset \n            imgs: List[str], the image file names\n            labels: List[int], the 0/1 label for each image\n            resize: None or int, whether downsample or upsample the image to certain size\n            inference: bool, True for the data without the label\n        \"\"\"\n        self.img_path = img_path\n        self.resize = resize\n        self.imgs = imgs\n        self.labels = labels\n        self.inference = inference\n\n        # resizing image for better processing in cnn\n        self.pre_process = transforms.Compose([\n                                            transforms.Resize((224,224)),\n                                            transforms.CenterCrop((224, 224)),\n                                            \n                                            ])\n\n\n        # first transform the images to tensor format, then normalize the pixel values\n        self.totensor = transforms.Compose([\n                                    transforms.ToTensor(),\n                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                                    ])\n\n        if resize is not None:\n            self.resampling = transforms.Resize((resize, resize))\n\n    def __getitem__(self, index):\n        image_path = os.path.join(self.img_path, self.imgs[index])\n        img = Image.open(image_path).convert('RGB')\n        img = self.pre_process(img)\n        img_tensor = self.totensor(img)\n        if self.resize is not None:\n            img_tensor = self.resampling(img_tensor)\n        if not self.inference:\n            label = self.labels[index]\n            return img_tensor, label\n        else:\n            return img_tensor\n\n    def __len__(self):\n        return len(self.imgs)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T08:30:31.721252Z","iopub.execute_input":"2023-02-18T08:30:31.721636Z","iopub.status.idle":"2023-02-18T08:30:31.733671Z","shell.execute_reply.started":"2023-02-18T08:30:31.7216Z","shell.execute_reply":"2023-02-18T08:30:31.732303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\nTEST_BATCH_SIZE = 1000\n\n# create the dataset\ntrain_ds = CelebADataset(images_folder, train_df['id'], train_df['label'])\nvalid_ds = CelebADataset(images_folder, valid_df['id'], valid_df['label'])\n\n# build the dataloader\ntrain_loader = torch.utils.data.DataLoader(\n    train_ds, batch_size=BATCH_SIZE, shuffle=True\n)\nvalid_loader = torch.utils.data.DataLoader(\n    valid_ds, batch_size=TEST_BATCH_SIZE\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T08:30:31.735611Z","iopub.execute_input":"2023-02-18T08:30:31.736299Z","iopub.status.idle":"2023-02-18T08:30:31.749732Z","shell.execute_reply.started":"2023-02-18T08:30:31.736258Z","shell.execute_reply":"2023-02-18T08:30:31.748731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds[0][0].size(), train_ds[0][1]","metadata":{"execution":{"iopub.status.busy":"2023-02-18T08:30:31.75218Z","iopub.execute_input":"2023-02-18T08:30:31.752514Z","iopub.status.idle":"2023-02-18T08:30:31.84033Z","shell.execute_reply.started":"2023-02-18T08:30:31.75247Z","shell.execute_reply":"2023-02-18T08:30:31.839454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer(object):\n    \"\"\"\n        A learning pipeline to train and validate the model.\n    \"\"\"\n    def __init__(self, model, criterion, optimizer, max_epoch):\n        \"\"\"\n            model: nn model\n            criterion: loss function\n            optimizer: optimizer\n            max_epoch: maximum training epoch\n        \"\"\"\n        self.model = model.to(device)\n        self.criterion = criterion.to(device)\n        self.optimizer = optimizer\n        self.max_epoch = max_epoch\n\n    def run(self,train_loader, valid_loader):\n        \"\"\"\n            Main entry\n                train_loader: training dataset, each item is (img, label)\n                valid_loader: validation dataset, each item is (img, label)\n        \"\"\"\n        # calculate the inital loss and accu on validation set\n        valid_best_loss = self.validate(-1, valid_loader, best_loss=None)\n        for epoch in range(self.max_epoch):\n            self.train(epoch, train_loader)\n            # save the checkpoint with the lowest validation loss\n            valid_best_loss = self.validate(epoch, valid_loader, valid_best_loss)\n\n    def train(self, epoch, loader):\n        \"\"\"\n            Single training loop\n                epoch: int, current epoch index\n                loader: training loader\n        \"\"\"\n        # switch to the train mode, calculate the gradient\n        self.model.train()\n        running_loss, total, correct = 0.0, 0, 0\n        with tqdm(enumerate(loader, 0), mininterval=10) as tepoch:\n            for i, data in tepoch:\n                # get the inputs; data is a list of [inputs, labels]\n                # inputs: tensor, (batch_size, image_size, image_size)\n                # labels: tensor, (batch_size, 1)\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                \n                optimizer.step()\n\n\n                # calculate the metric\n                match, number = self.cal_metric(outputs.data, labels)\n\n                # gather statistics\n                total += number\n                correct += match\n                running_loss += loss.item()\n                tepoch.set_postfix(loss=loss.item(), accuracy=100. * correct / total)\n\n        running_loss /= len(loader)\n\n        print('Training | Epoch: {}| Loss: {:.3f} | Accuracy on train images: {:.1f}'.format \\\n              (epoch+1, running_loss, 100 * correct / total))\n\n    def validate(self, epoch, loader, best_loss=None):\n        \"\"\"\n            Single evaluation loop\n                epoch: int, current epoch index\n                loader: validation loader\n                best_loss: float, current best loss\n        \"\"\"\n        # switch to the evaluation mode, do not need to calculate the gradient\n        self.model.eval()\n        running_loss, total, correct = 0.0, 0, 0\n        for i, data in tqdm(enumerate(loader)):\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            # calculate the metric\n            match, number = self.cal_metric(outputs.data, labels)\n\n            # gather statistics\n            total += number\n            correct += match\n            running_loss += loss.item()\n\n        running_loss /= len(loader)\n\n        if best_loss is None or running_loss < best_loss:\n            # if a better loss appears, save the checkpoint\n            save_file = 'best_epoch{}_loss{:.2f}_accu{:.2f}.pt'.format(epoch+1, running_loss, 100 * correct / total)\n            print('Save to file: ', save_file)\n            torch.save(self.model, save_file)\n\n            # overwrite the best_checkpoint.pt file\n            torch.save(self.model, 'best_checkpoint.pt')\n\n            best_loss = running_loss\n\n        print('Validation | Epoch: {}| Loss: {:.3f} | Accuracy on val images: {:.1f}'.format \\\n              (epoch+1, running_loss,100 * correct / total))\n\n        return best_loss\n\n\n    def cal_metric(self, outputs, labels):\n        \"\"\"\n            Calculate the accuracy\n                outputs: tensor (batch_size, number_class), the output of the model\n                labels: tensor (batch_size, 1), the ground truth\n        \"\"\"\n        # compare predictions to ground truth\n        _, predicted = torch.max(outputs, 1)\n        number = labels.size(0)\n        correct = (predicted == labels).sum().item()\n        return correct, number","metadata":{"execution":{"iopub.status.busy":"2023-02-18T08:30:31.842507Z","iopub.execute_input":"2023-02-18T08:30:31.843088Z","iopub.status.idle":"2023-02-18T08:30:31.861616Z","shell.execute_reply.started":"2023-02-18T08:30:31.843052Z","shell.execute_reply":"2023-02-18T08:30:31.860503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True) #pretrained model via torch.hub\n\nprint(model)\nprint('Model Parameters ', sum(p.numel() for p in model.parameters()))\nprint('Trainable Parameters ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n","metadata":{"execution":{"iopub.status.busy":"2023-02-18T08:30:31.864685Z","iopub.execute_input":"2023-02-18T08:30:31.864992Z","iopub.status.idle":"2023-02-18T08:30:45.424649Z","shell.execute_reply.started":"2023-02-18T08:30:31.864958Z","shell.execute_reply":"2023-02-18T08:30:45.423632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\nNUM_EPOCH = 10\nLEARNING_RATE = 0.001\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n# optimizer = optim.Adam(model.parameters()) #, lr=LEARNING_RATE, momentum=0.9\ntrainer = Trainer(model, criterion, optimizer, max_epoch=NUM_EPOCH)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T08:30:45.428156Z","iopub.execute_input":"2023-02-18T08:30:45.428548Z","iopub.status.idle":"2023-02-18T08:30:47.580156Z","shell.execute_reply.started":"2023-02-18T08:30:45.428516Z","shell.execute_reply":"2023-02-18T08:30:47.578886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.run(train_loader, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T08:30:47.581863Z","iopub.execute_input":"2023-02-18T08:30:47.582248Z","iopub.status.idle":"2023-02-18T09:17:10.572214Z","shell.execute_reply.started":"2023-02-18T08:30:47.582209Z","shell.execute_reply":"2023-02-18T09:17:10.571197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    \"\"\"\n        The test dataset module\n    \"\"\"\n    def __init__(self, imgs, resize=None):\n        \"\"\"\n            Similar with CelebADataset \n                imgs: open images\n                resize: None or int, whether downsample or upsample the image to certain size\n        \"\"\"\n        self.imgs = imgs\n        self.resize = resize\n\n        self.pre_process = transforms.Compose([\n                                            transforms.Resize((224,224)),\n                                            transforms.CenterCrop((224, 224)),\n                                            \n                                            ])\n\n\n        # first transform the images to tensor format, then normalize the pixel values\n        self.totensor = transforms.Compose([\n                                    transforms.ToTensor(),\n                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                                    ])\n\n        if resize is not None:\n            self.resampling = transforms.Resize((resize, resize))\n\n    def __getitem__(self, index):\n        img = self.imgs[index]\n        img = self.pre_process(img)\n        img_tensor = self.totensor(img)\n        if self.resize is not None:\n            img_tensor = self.resampling(img_tensor)\n        return img_tensor\n\n    def __len__(self):\n        return len(self.imgs)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T09:17:10.574133Z","iopub.execute_input":"2023-02-18T09:17:10.575151Z","iopub.status.idle":"2023-02-18T09:17:10.585692Z","shell.execute_reply.started":"2023-02-18T09:17:10.575112Z","shell.execute_reply":"2023-02-18T09:17:10.584716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_BATCH_SIZE=1000\n\ndef predict(model_path, test_file):\n    \"\"\"\n        Load the model and use it to predict test file \n    \"\"\"\n    test_data = torch.load(test_file)\n    test_dataset = TestDataset(test_data)\n    test_loader = torch.utils.data.DataLoader(\n                    test_dataset, batch_size=TEST_BATCH_SIZE\n                )\n\n    model = torch.load(model_path)\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        # labels are not available for the actual test set\n        for feature in tqdm(test_loader):\n            # calculate outputs by running images through the network\n            outputs = model(feature.to(device))\n            _, predicted = torch.max(outputs.data, 1)\n            preds.extend(predicted.tolist())\n\n    return preds","metadata":{"execution":{"iopub.status.busy":"2023-02-18T09:17:10.587078Z","iopub.execute_input":"2023-02-18T09:17:10.587729Z","iopub.status.idle":"2023-02-18T09:17:10.59856Z","shell.execute_reply.started":"2023-02-18T09:17:10.587693Z","shell.execute_reply":"2023-02-18T09:17:10.597558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"best_checkpoint.pt\"\ntest_file = \"/kaggle/input/cs190-winter23-deep-learning-mp1/test_img.pt\"\npreds = predict(model_path,test_file)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T09:17:10.599999Z","iopub.execute_input":"2023-02-18T09:17:10.600636Z","iopub.status.idle":"2023-02-18T09:17:19.965477Z","shell.execute_reply.started":"2023-02-18T09:17:10.600591Z","shell.execute_reply":"2023-02-18T09:17:19.964338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'id': list(range(len(preds))),'label': preds})\ndf.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T09:17:19.969911Z","iopub.execute_input":"2023-02-18T09:17:19.972655Z","iopub.status.idle":"2023-02-18T09:17:19.991624Z","shell.execute_reply.started":"2023-02-18T09:17:19.972616Z","shell.execute_reply":"2023-02-18T09:17:19.990345Z"},"trusted":true},"execution_count":null,"outputs":[]}]}